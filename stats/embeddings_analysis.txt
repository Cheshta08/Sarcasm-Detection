Current date and time: 2024-08-12 02:10:37.003702

11000

Getting deep-mojis for each tweet in data_frame_train.csv...
Couldn't find a strong emoji prediction for 226 emojis
11000

Getting deep-mojis for each tweet in data_frame_test.csv...
Couldn't find a strong emoji prediction for 100 emojis

Building random vector of mappings with dimension 100...

Loading vector mappings from glove.6B.100d.txt...
Found 400000 word vectors with embedding dimension 100

Loading vector mappings from emoji_embeddings_100d.txt...
Found 1661 word vectors with embedding dimension 100
Vector mappings have variance  0.330294298841409
Vector mappings have variance  0.1652108203125
Vector mappings have variance  0.0008966506496385807
Vector mappings have variance  0.0008966506496385807
Vector mappings have variance  0.0008966506496385807
Vector mappings have variance  0.330294298841409
Vector mappings have variance  0.1652108203125
Vector mappings have variance  0.0008966506496385807
Vector mappings have variance  0.0008966506496385807
Vector mappings have variance  0.0008966506496385807
Shape of concatenated train features:  (11000, 200)
Shape of concatenated test features:  (3742, 200)
Shape of summed train features:  (11000, 100)
Shape of summed test features:  (3742, 100)

==================================================================
SVM analysis for: Random emb
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.594
Precision: 0.602
Recall: 0.594
F_score: 0.597

              precision    recall  f1-score   support

           0       0.68      0.64      0.66      2323
           1       0.47      0.52      0.49      1419

    accuracy                           0.59      3742
   macro avg       0.58      0.58      0.58      3742
weighted avg       0.60      0.59      0.60      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.594
Precision: 0.603
Recall: 0.594
F_score: 0.598

              precision    recall  f1-score   support

           0       0.69      0.64      0.66      2323
           1       0.47      0.52      0.49      1419

    accuracy                           0.59      3742
   macro avg       0.58      0.58      0.58      3742
weighted avg       0.60      0.59      0.60      3742

Completion time of the Random emb SVM model: 3.618 s = 0.060 min

==================================================================
NN analysis for: Random emb
==================================================================


Building Bow NN model...
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                        │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:49[0m 669ms/step - accuracy: 0.5000 - f1_score: nan - loss: 0.7855
[1m 44/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5225 - f1_score: nan - loss: 0.7616    
[1m 89/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5427 - f1_score: nan - loss: 0.7390
[1m127/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5510 - f1_score: nan - loss: 0.7287
[1m181/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5572 - f1_score: nan - loss: 0.7194
[1m236/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5610 - f1_score: nan - loss: 0.7126
[1m299/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5629 - f1_score: nan - loss: 0.7073
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.5636 - f1_score: nan - loss: 0.7043
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 30ms/step - accuracy: 0.6875 - f1_score: nan - loss: 0.6438
[1m 69/344[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m0s[0m 747us/step - accuracy: 0.5785 - f1_score: nan - loss: 0.6635
[1m135/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 759us/step - accuracy: 0.5805 - f1_score: nan - loss: 0.6628
[1m201/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 759us/step - accuracy: 0.5829 - f1_score: nan - loss: 0.6621
[1m254/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 800us/step - accuracy: 0.5841 - f1_score: nan - loss: 0.6619
[1m309/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 821us/step - accuracy: 0.5854 - f1_score: nan - loss: 0.6617
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 837us/step - accuracy: 0.5865 - f1_score: nan - loss: 0.6614
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 34ms/step - accuracy: 0.6250 - f1_score: nan - loss: 0.6249
[1m 45/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5997 - f1_score: nan - loss: 0.6525  
[1m 89/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6082 - f1_score: nan - loss: 0.6529
[1m135/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6119 - f1_score: nan - loss: 0.6527
[1m183/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6135 - f1_score: nan - loss: 0.6528
[1m225/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6148 - f1_score: nan - loss: 0.6526
[1m270/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6158 - f1_score: nan - loss: 0.6524
[1m325/344[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - accuracy: 0.6166 - f1_score: nan - loss: 0.6522
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.6169 - f1_score: nan - loss: 0.6521
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 32ms/step - accuracy: 0.5625 - f1_score: nan - loss: 0.6659
[1m 44/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6310 - f1_score: nan - loss: 0.6389  
[1m 88/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6299 - f1_score: nan - loss: 0.6420
[1m147/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6286 - f1_score: nan - loss: 0.6434
[1m210/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 969us/step - accuracy: 0.6295 - f1_score: nan - loss: 0.6437
[1m273/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 930us/step - accuracy: 0.6300 - f1_score: nan - loss: 0.6440
[1m340/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 894us/step - accuracy: 0.6306 - f1_score: nan - loss: 0.6443
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 901us/step - accuracy: 0.6306 - f1_score: nan - loss: 0.6443
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 31ms/step - accuracy: 0.6875 - f1_score: nan - loss: 0.6218
[1m 46/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6427 - f1_score: nan - loss: 0.6447  
[1m 96/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6418 - f1_score: nan - loss: 0.6448
[1m136/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6409 - f1_score: nan - loss: 0.6445
[1m173/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6398 - f1_score: nan - loss: 0.6443
[1m215/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6388 - f1_score: nan - loss: 0.6439
[1m255/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6385 - f1_score: nan - loss: 0.6436
[1m297/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6387 - f1_score: nan - loss: 0.6432
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.6392 - f1_score: nan - loss: 0.6426

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m15s[0m 135ms/step - accuracy: 0.8125 - f1_score: nan - loss: 0.5657
[1m 61/117[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 848us/step - accuracy: 0.7268 - f1_score: nan - loss: 0.5996 
[1m114/117[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 895us/step - accuracy: 0.6631 - f1_score: nan - loss: 0.6419
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 916us/step - accuracy: 0.6625 - f1_score: nan - loss: 0.6421

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m5s[0m 47ms/step
[1m 80/117[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 643us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 733us/step
Accuracy: 0.645
Precision: 0.629
Recall: 0.645
F_score: 0.627

              precision    recall  f1-score   support

           0       0.68      0.81      0.74      2323
           1       0.55      0.37      0.44      1419

    accuracy                           0.65      3742
   macro avg       0.61      0.59      0.59      3742
weighted avg       0.63      0.65      0.63      3742

2415 examples predicted correctly.
962 examples predicted 1.
2780 examples predicted 0.
Completion time of the Random emb NN model: 3.220 s = 0.054 min

==================================================================
SVM analysis for: Just word emb
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.586
Precision: 0.577
Recall: 0.586
F_score: 0.581

              precision    recall  f1-score   support

           0       0.66      0.70      0.68      2323
           1       0.45      0.40      0.42      1419

    accuracy                           0.59      3742
   macro avg       0.55      0.55      0.55      3742
weighted avg       0.58      0.59      0.58      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.583
Precision: 0.575
Recall: 0.583
F_score: 0.578

              precision    recall  f1-score   support

           0       0.65      0.69      0.67      2323
           1       0.44      0.40      0.42      1419

    accuracy                           0.58      3742
   macro avg       0.55      0.55      0.55      3742
weighted avg       0.58      0.58      0.58      3742

Completion time of the Just word emb SVM model: 7.421 s = 0.124 min

==================================================================
NN analysis for: Just word emb
==================================================================


Building Bow NN model...
Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_2 (Dense)                      │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_3 (Dense)                      │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:20[0m 585ms/step - accuracy: 0.5625 - f1_score: nan - loss: 0.7549
[1m 52/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 996us/step - accuracy: 0.5678 - f1_score: nan - loss: 0.7798  
[1m100/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5609 - f1_score: nan - loss: 0.7786  
[1m145/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5584 - f1_score: nan - loss: 0.7736
[1m190/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5588 - f1_score: nan - loss: 0.7662
[1m234/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5591 - f1_score: nan - loss: 0.7598
[1m276/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5598 - f1_score: nan - loss: 0.7541
[1m316/344[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - accuracy: 0.5604 - f1_score: nan - loss: 0.7493
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.5610 - f1_score: nan - loss: 0.7460
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 29ms/step - accuracy: 0.4688 - f1_score: nan - loss: 0.7245
[1m 56/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 918us/step - accuracy: 0.5744 - f1_score: nan - loss: 0.6703
[1m119/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 859us/step - accuracy: 0.5883 - f1_score: nan - loss: 0.6629
[1m171/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 893us/step - accuracy: 0.5938 - f1_score: nan - loss: 0.6603
[1m234/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 868us/step - accuracy: 0.5976 - f1_score: nan - loss: 0.6585
[1m280/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 904us/step - accuracy: 0.5993 - f1_score: nan - loss: 0.6578
[1m330/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 920us/step - accuracy: 0.6010 - f1_score: nan - loss: 0.6571
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 930us/step - accuracy: 0.6015 - f1_score: nan - loss: 0.6570
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 30ms/step - accuracy: 0.5312 - f1_score: nan - loss: 0.7018
[1m 51/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6504 - f1_score: nan - loss: 0.6341  
[1m 97/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6465 - f1_score: nan - loss: 0.6370
[1m160/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 955us/step - accuracy: 0.6439 - f1_score: nan - loss: 0.6389
[1m230/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 885us/step - accuracy: 0.6417 - f1_score: nan - loss: 0.6400
[1m275/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 925us/step - accuracy: 0.6406 - f1_score: nan - loss: 0.6404
[1m333/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 917us/step - accuracy: 0.6392 - f1_score: nan - loss: 0.6410
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 913us/step - accuracy: 0.6390 - f1_score: nan - loss: 0.6410
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m8s[0m 24ms/step - accuracy: 0.7188 - f1_score: nan - loss: 0.5833
[1m 52/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 989us/step - accuracy: 0.6334 - f1_score: nan - loss: 0.6326
[1m120/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 844us/step - accuracy: 0.6269 - f1_score: nan - loss: 0.6361
[1m168/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 901us/step - accuracy: 0.6279 - f1_score: nan - loss: 0.6366
[1m220/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 916us/step - accuracy: 0.6299 - f1_score: nan - loss: 0.6368
[1m289/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 872us/step - accuracy: 0.6324 - f1_score: nan - loss: 0.6366
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 847us/step - accuracy: 0.6339 - f1_score: nan - loss: 0.6366
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 34ms/step - accuracy: 0.5625 - f1_score: nan - loss: 0.7051
[1m 52/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6229 - f1_score: nan - loss: 0.6475  
[1m112/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 918us/step - accuracy: 0.6338 - f1_score: nan - loss: 0.6400
[1m174/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 882us/step - accuracy: 0.6379 - f1_score: nan - loss: 0.6375
[1m236/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 862us/step - accuracy: 0.6403 - f1_score: nan - loss: 0.6361
[1m281/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 904us/step - accuracy: 0.6415 - f1_score: nan - loss: 0.6354
[1m332/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 921us/step - accuracy: 0.6424 - f1_score: nan - loss: 0.6349
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 929us/step - accuracy: 0.6425 - f1_score: nan - loss: 0.6348

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m14s[0m 127ms/step - accuracy: 0.7500 - f1_score: nan - loss: 0.6095
[1m 47/117[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6706 - f1_score: nan - loss: 0.6171   
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 949us/step - accuracy: 0.6171 - f1_score: nan - loss: 0.6551

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 34ms/step
[1m100/117[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 513us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 698us/step
Accuracy: 0.621
Precision: 0.610
Recall: 0.621
F_score: 0.614

              precision    recall  f1-score   support

           0       0.68      0.74      0.71      2323
           1       0.50      0.42      0.46      1419

    accuracy                           0.62      3742
   macro avg       0.59      0.58      0.58      3742
weighted avg       0.61      0.62      0.61      3742

2325 examples predicted correctly.
1188 examples predicted 1.
2554 examples predicted 0.
Completion time of the Just word emb NN model: 2.886 s = 0.048 min

==================================================================
SVM analysis for: Present emojis
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.379
Precision: 0.452
Recall: 0.379
F_score: 0.241

              precision    recall  f1-score   support

           0       0.50      0.03      0.06      2323
           1       0.37      0.95      0.54      1419

    accuracy                           0.38      3742
   macro avg       0.44      0.49      0.30      3742
weighted avg       0.45      0.38      0.24      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.631
Precision: 0.629
Recall: 0.631
F_score: 0.524

              precision    recall  f1-score   support

           0       0.63      0.97      0.77      2323
           1       0.62      0.07      0.13      1419

    accuracy                           0.63      3742
   macro avg       0.63      0.52      0.45      3742
weighted avg       0.63      0.63      0.52      3742

Completion time of the Present emojis SVM model: 1.551 s = 0.026 min

==================================================================
NN analysis for: Present emojis
==================================================================


Building Bow NN model...
Model: "sequential_2"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_4 (Dense)                      │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_5 (Dense)                      │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:25[0m 599ms/step - accuracy: 0.4688 - f1_score: nan - loss: 0.7673
[1m 47/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4112 - f1_score: nan - loss: 0.7751    
[1m 93/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4259 - f1_score: nan - loss: 0.7616
[1m136/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4356 - f1_score: nan - loss: 0.7535
[1m177/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4440 - f1_score: nan - loss: 0.7469
[1m228/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4541 - f1_score: nan - loss: 0.7400
[1m275/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4629 - f1_score: nan - loss: 0.7346
[1m333/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 1ms/step - accuracy: 0.4727 - f1_score: nan - loss: 0.7289
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.4746 - f1_score: nan - loss: 0.7279
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 33ms/step - accuracy: 0.5000 - f1_score: nan - loss: 0.6959
[1m 71/344[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m0s[0m 722us/step - accuracy: 0.6069 - f1_score: nan - loss: 0.6651
[1m143/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 710us/step - accuracy: 0.6096 - f1_score: nan - loss: 0.6632
[1m211/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 719us/step - accuracy: 0.6098 - f1_score: nan - loss: 0.6619
[1m279/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 725us/step - accuracy: 0.6101 - f1_score: nan - loss: 0.6609
[1m336/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 752us/step - accuracy: 0.6110 - f1_score: nan - loss: 0.6600
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 759us/step - accuracy: 0.6111 - f1_score: nan - loss: 0.6599
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 34ms/step - accuracy: 0.5938 - f1_score: nan - loss: 0.6223
[1m 51/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6396 - f1_score: nan - loss: 0.6354  
[1m123/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 829us/step - accuracy: 0.6345 - f1_score: nan - loss: 0.6400
[1m167/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 911us/step - accuracy: 0.6331 - f1_score: nan - loss: 0.6410
[1m215/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 941us/step - accuracy: 0.6323 - f1_score: nan - loss: 0.6417
[1m284/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 890us/step - accuracy: 0.6313 - f1_score: nan - loss: 0.6425
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 854us/step - accuracy: 0.6308 - f1_score: nan - loss: 0.6429
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 33ms/step - accuracy: 0.5938 - f1_score: nan - loss: 0.6987
[1m 45/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6463 - f1_score: nan - loss: 0.6419  
[1m 93/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6433 - f1_score: nan - loss: 0.6400
[1m147/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6392 - f1_score: nan - loss: 0.6403
[1m195/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6385 - f1_score: nan - loss: 0.6399
[1m242/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6379 - f1_score: nan - loss: 0.6397
[1m294/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6378 - f1_score: nan - loss: 0.6397
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.6378 - f1_score: nan - loss: 0.6395
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 35ms/step - accuracy: 0.6562 - f1_score: nan - loss: 0.6109
[1m 58/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 884us/step - accuracy: 0.6429 - f1_score: nan - loss: 0.6295
[1m125/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 814us/step - accuracy: 0.6389 - f1_score: nan - loss: 0.6340
[1m177/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 858us/step - accuracy: 0.6377 - f1_score: nan - loss: 0.6345
[1m226/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 897us/step - accuracy: 0.6372 - f1_score: nan - loss: 0.6345
[1m280/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 906us/step - accuracy: 0.6368 - f1_score: nan - loss: 0.6346
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 871us/step - accuracy: 0.6367 - f1_score: nan - loss: 0.6347

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m13s[0m 115ms/step - accuracy: 0.8438 - f1_score: nan - loss: 0.5658
[1m 58/117[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 882us/step - accuracy: 0.7321 - f1_score: nan - loss: 0.5969 
[1m113/117[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 902us/step - accuracy: 0.6687 - f1_score: nan - loss: 0.6353
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 923us/step - accuracy: 0.6675 - f1_score: nan - loss: 0.6356

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 38ms/step
[1m 91/117[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 563us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 706us/step
Accuracy: 0.642
Precision: 0.630
Recall: 0.642
F_score: 0.631

              precision    recall  f1-score   support

           0       0.69      0.78      0.73      2323
           1       0.54      0.42      0.47      1419

    accuracy                           0.64      3742
   macro avg       0.61      0.60      0.60      3742
weighted avg       0.63      0.64      0.63      3742

2404 examples predicted correctly.
1101 examples predicted 1.
2641 examples predicted 0.
Completion time of the Present emojis NN model: 2.871 s = 0.048 min

==================================================================
SVM analysis for: Deepmojis
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.734
Precision: 0.751
Recall: 0.734
F_score: 0.738

              precision    recall  f1-score   support

           0       0.83      0.72      0.77      2323
           1       0.62      0.76      0.68      1419

    accuracy                           0.73      3742
   macro avg       0.73      0.74      0.73      3742
weighted avg       0.75      0.73      0.74      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.736
Precision: 0.753
Recall: 0.736
F_score: 0.740

              precision    recall  f1-score   support

           0       0.83      0.72      0.77      2323
           1       0.63      0.76      0.69      1419

    accuracy                           0.74      3742
   macro avg       0.73      0.74      0.73      3742
weighted avg       0.75      0.74      0.74      3742

Completion time of the Deepmojis SVM model: 6.058 s = 0.101 min

==================================================================
NN analysis for: Deepmojis
==================================================================


Building Bow NN model...
Model: "sequential_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_6 (Dense)                      │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_7 (Dense)                      │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:16[0m 572ms/step - accuracy: 0.4375 - f1_score: nan - loss: 0.7608
[1m 51/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4772 - f1_score: nan - loss: 0.7286    
[1m 97/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4868 - f1_score: nan - loss: 0.7221
[1m138/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4957 - f1_score: nan - loss: 0.7168
[1m185/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5054 - f1_score: nan - loss: 0.7118
[1m232/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5128 - f1_score: nan - loss: 0.7078
[1m270/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5177 - f1_score: nan - loss: 0.7051
[1m316/344[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - accuracy: 0.5230 - f1_score: nan - loss: 0.7022
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.5260 - f1_score: nan - loss: 0.7006
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 29ms/step - accuracy: 0.7188 - f1_score: nan - loss: 0.6396
[1m 67/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 771us/step - accuracy: 0.6020 - f1_score: nan - loss: 0.6601
[1m140/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 729us/step - accuracy: 0.6059 - f1_score: nan - loss: 0.6577
[1m212/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 717us/step - accuracy: 0.6096 - f1_score: nan - loss: 0.6558
[1m285/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 709us/step - accuracy: 0.6132 - f1_score: nan - loss: 0.6540
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 711us/step - accuracy: 0.6157 - f1_score: nan - loss: 0.6528
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 21ms/step - accuracy: 0.5312 - f1_score: nan - loss: 0.6841
[1m 56/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 933us/step - accuracy: 0.6363 - f1_score: nan - loss: 0.6420
[1m112/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 930us/step - accuracy: 0.6401 - f1_score: nan - loss: 0.6405
[1m155/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 997us/step - accuracy: 0.6396 - f1_score: nan - loss: 0.6404
[1m204/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6398 - f1_score: nan - loss: 0.6399  
[1m251/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6402 - f1_score: nan - loss: 0.6393
[1m314/344[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 983us/step - accuracy: 0.6407 - f1_score: nan - loss: 0.6388
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 974us/step - accuracy: 0.6409 - f1_score: nan - loss: 0.6387
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m15s[0m 46ms/step - accuracy: 0.5312 - f1_score: nan - loss: 0.6738
[1m 51/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6355 - f1_score: nan - loss: 0.6301  
[1m 97/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6343 - f1_score: nan - loss: 0.6348
[1m146/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6375 - f1_score: nan - loss: 0.6343
[1m199/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6389 - f1_score: nan - loss: 0.6345
[1m240/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6395 - f1_score: nan - loss: 0.6345
[1m261/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6399 - f1_score: nan - loss: 0.6344
[1m308/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6405 - f1_score: nan - loss: 0.6343
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.6409 - f1_score: nan - loss: 0.6341
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m8s[0m 25ms/step - accuracy: 0.6250 - f1_score: nan - loss: 0.6201
[1m 48/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6262 - f1_score: nan - loss: 0.6363 
[1m 89/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6267 - f1_score: nan - loss: 0.6365
[1m149/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6323 - f1_score: nan - loss: 0.6338
[1m216/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6367 - f1_score: nan - loss: 0.6319
[1m287/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 932us/step - accuracy: 0.6393 - f1_score: nan - loss: 0.6306
[1m339/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 939us/step - accuracy: 0.6402 - f1_score: nan - loss: 0.6304
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 947us/step - accuracy: 0.6403 - f1_score: nan - loss: 0.6304

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m13s[0m 118ms/step - accuracy: 0.8125 - f1_score: nan - loss: 0.5784
[1m 59/117[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 869us/step - accuracy: 0.7040 - f1_score: nan - loss: 0.6082 
[1m113/117[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 897us/step - accuracy: 0.6460 - f1_score: nan - loss: 0.6424
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 918us/step - accuracy: 0.6453 - f1_score: nan - loss: 0.6426

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 35ms/step
[1m 74/117[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 696us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 883us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 893us/step
Accuracy: 0.631
Precision: 0.617
Recall: 0.631
F_score: 0.620

              precision    recall  f1-score   support

           0       0.68      0.77      0.72      2323
           1       0.52      0.40      0.45      1419

    accuracy                           0.63      3742
   macro avg       0.60      0.59      0.59      3742
weighted avg       0.62      0.63      0.62      3742

2362 examples predicted correctly.
1099 examples predicted 1.
2643 examples predicted 0.
Completion time of the Deepmojis NN model: 2.968 s = 0.049 min

==================================================================
SVM analysis for: All emojis
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.733
Precision: 0.748
Recall: 0.733
F_score: 0.736

              precision    recall  f1-score   support

           0       0.82      0.72      0.77      2323
           1       0.62      0.75      0.68      1419

    accuracy                           0.73      3742
   macro avg       0.72      0.74      0.73      3742
weighted avg       0.75      0.73      0.74      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.730
Precision: 0.748
Recall: 0.730
F_score: 0.734

              precision    recall  f1-score   support

           0       0.83      0.71      0.77      2323
           1       0.62      0.76      0.68      1419

    accuracy                           0.73      3742
   macro avg       0.72      0.73      0.72      3742
weighted avg       0.75      0.73      0.73      3742

Completion time of the All emojis SVM model: 7.466 s = 0.124 min

==================================================================
NN analysis for: All emojis
==================================================================


Building Bow NN model...
Model: "sequential_4"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_8 (Dense)                      │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_9 (Dense)                      │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:54[0m 684ms/step - accuracy: 0.4062 - f1_score: nan - loss: 0.8167
[1m 55/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 929us/step - accuracy: 0.4248 - f1_score: nan - loss: 0.8328  
[1m106/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 962us/step - accuracy: 0.4315 - f1_score: nan - loss: 0.8156
[1m150/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4370 - f1_score: nan - loss: 0.8035  
[1m194/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4434 - f1_score: nan - loss: 0.7927
[1m241/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4506 - f1_score: nan - loss: 0.7828
[1m292/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4584 - f1_score: nan - loss: 0.7736
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.4666 - f1_score: nan - loss: 0.7652
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 27ms/step - accuracy: 0.6250 - f1_score: nan - loss: 0.6669
[1m 44/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6351 - f1_score: nan - loss: 0.6476 
[1m 89/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6272 - f1_score: nan - loss: 0.6507
[1m155/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 996us/step - accuracy: 0.6239 - f1_score: nan - loss: 0.6518
[1m223/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 918us/step - accuracy: 0.6247 - f1_score: nan - loss: 0.6512
[1m293/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 870us/step - accuracy: 0.6259 - f1_score: nan - loss: 0.6504
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 887us/step - accuracy: 0.6267 - f1_score: nan - loss: 0.6498
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 26ms/step - accuracy: 0.4688 - f1_score: nan - loss: 0.6296
[1m 47/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6054 - f1_score: nan - loss: 0.6471 
[1m 95/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6200 - f1_score: nan - loss: 0.6427
[1m142/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6282 - f1_score: nan - loss: 0.6403
[1m197/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6316 - f1_score: nan - loss: 0.6401
[1m262/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 971us/step - accuracy: 0.6352 - f1_score: nan - loss: 0.6391
[1m337/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 904us/step - accuracy: 0.6376 - f1_score: nan - loss: 0.6384
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 906us/step - accuracy: 0.6378 - f1_score: nan - loss: 0.6383
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m8s[0m 26ms/step - accuracy: 0.7188 - f1_score: nan - loss: 0.5600
[1m 46/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6313 - f1_score: nan - loss: 0.6332 
[1m 92/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6331 - f1_score: nan - loss: 0.6358
[1m145/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6353 - f1_score: nan - loss: 0.6366
[1m214/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 956us/step - accuracy: 0.6379 - f1_score: nan - loss: 0.6358
[1m285/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 895us/step - accuracy: 0.6396 - f1_score: nan - loss: 0.6350
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 886us/step - accuracy: 0.6408 - f1_score: nan - loss: 0.6346
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 35ms/step - accuracy: 0.6875 - f1_score: nan - loss: 0.5851
[1m 54/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 955us/step - accuracy: 0.6647 - f1_score: nan - loss: 0.6228
[1m120/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 852us/step - accuracy: 0.6543 - f1_score: nan - loss: 0.6286
[1m193/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 793us/step - accuracy: 0.6517 - f1_score: nan - loss: 0.6296
[1m256/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 793us/step - accuracy: 0.6504 - f1_score: nan - loss: 0.6302
[1m327/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 774us/step - accuracy: 0.6498 - f1_score: nan - loss: 0.6305
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 777us/step - accuracy: 0.6498 - f1_score: nan - loss: 0.6305

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19s[0m 169ms/step - accuracy: 0.7812 - f1_score: nan - loss: 0.5807
[1m 70/117[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 739us/step - accuracy: 0.6744 - f1_score: nan - loss: 0.6187 
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 803us/step - accuracy: 0.6368 - f1_score: nan - loss: 0.6437

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m4s[0m 40ms/step
[1m 63/117[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 809us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 838us/step
Accuracy: 0.628
Precision: 0.615
Recall: 0.628
F_score: 0.617

              precision    recall  f1-score   support

           0       0.68      0.77      0.72      2323
           1       0.51      0.40      0.45      1419

    accuracy                           0.63      3742
   macro avg       0.60      0.58      0.59      3742
weighted avg       0.61      0.63      0.62      3742

2351 examples predicted correctly.
1116 examples predicted 1.
2626 examples predicted 0.
Completion time of the All emojis NN model: 2.946 s = 0.049 min

==================================================================
SVM analysis for: All concat
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.736
Precision: 0.753
Recall: 0.736
F_score: 0.740

              precision    recall  f1-score   support

           0       0.83      0.72      0.77      2323
           1       0.63      0.76      0.69      1419

    accuracy                           0.74      3742
   macro avg       0.73      0.74      0.73      3742
weighted avg       0.75      0.74      0.74      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.733
Precision: 0.750
Recall: 0.733
F_score: 0.737

              precision    recall  f1-score   support

           0       0.83      0.72      0.77      2323
           1       0.62      0.76      0.68      1419

    accuracy                           0.73      3742
   macro avg       0.73      0.74      0.73      3742
weighted avg       0.75      0.73      0.74      3742

Completion time of the All concat SVM model: 39.616 s = 0.660 min

==================================================================
NN analysis for: All concat
==================================================================


Building Bow NN model...
Model: "sequential_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_10 (Dense)                     │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_11 (Dense)                     │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:15[0m 570ms/step - accuracy: 0.4688 - f1_score: nan - loss: 0.7180
[1m 49/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4660 - f1_score: nan - loss: 0.7725    
[1m 96/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4670 - f1_score: nan - loss: 0.7668
[1m139/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4733 - f1_score: nan - loss: 0.7599
[1m181/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4790 - f1_score: nan - loss: 0.7539
[1m202/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4816 - f1_score: nan - loss: 0.7512
[1m244/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4874 - f1_score: nan - loss: 0.7459
[1m296/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - accuracy: 0.4944 - f1_score: nan - loss: 0.7400
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.5005 - f1_score: nan - loss: 0.7350
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 23ms/step - accuracy: 0.5625 - f1_score: nan - loss: 0.6588
[1m 72/344[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m0s[0m 705us/step - accuracy: 0.5963 - f1_score: nan - loss: 0.6597
[1m140/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 723us/step - accuracy: 0.6035 - f1_score: nan - loss: 0.6578
[1m213/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 713us/step - accuracy: 0.6086 - f1_score: nan - loss: 0.6564
[1m287/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 704us/step - accuracy: 0.6118 - f1_score: nan - loss: 0.6553
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 709us/step - accuracy: 0.6138 - f1_score: nan - loss: 0.6544
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 28ms/step - accuracy: 0.7188 - f1_score: nan - loss: 0.6315
[1m 62/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 826us/step - accuracy: 0.6344 - f1_score: nan - loss: 0.6378
[1m136/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 752us/step - accuracy: 0.6321 - f1_score: nan - loss: 0.6413
[1m199/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 775us/step - accuracy: 0.6335 - f1_score: nan - loss: 0.6416
[1m273/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 751us/step - accuracy: 0.6339 - f1_score: nan - loss: 0.6416
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 738us/step - accuracy: 0.6339 - f1_score: nan - loss: 0.6415
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 23ms/step - accuracy: 0.6562 - f1_score: nan - loss: 0.6023
[1m 51/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6326 - f1_score: nan - loss: 0.6355 
[1m 97/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6344 - f1_score: nan - loss: 0.6379
[1m158/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 963us/step - accuracy: 0.6349 - f1_score: nan - loss: 0.6382
[1m227/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 891us/step - accuracy: 0.6355 - f1_score: nan - loss: 0.6381
[1m296/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 852us/step - accuracy: 0.6359 - f1_score: nan - loss: 0.6378
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 849us/step - accuracy: 0.6362 - f1_score: nan - loss: 0.6375
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m11s[0m 34ms/step - accuracy: 0.6250 - f1_score: nan - loss: 0.6105
[1m 48/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6533 - f1_score: nan - loss: 0.6198  
[1m 97/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.6504 - f1_score: nan - loss: 0.6249
[1m158/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 965us/step - accuracy: 0.6446 - f1_score: nan - loss: 0.6285
[1m206/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 987us/step - accuracy: 0.6427 - f1_score: nan - loss: 0.6298
[1m259/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 981us/step - accuracy: 0.6419 - f1_score: nan - loss: 0.6306
[1m328/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 928us/step - accuracy: 0.6414 - f1_score: nan - loss: 0.6312
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 921us/step - accuracy: 0.6415 - f1_score: nan - loss: 0.6313

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m14s[0m 125ms/step - accuracy: 0.6875 - f1_score: nan - loss: 0.6170
[1m 60/117[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 852us/step - accuracy: 0.6577 - f1_score: nan - loss: 0.6284 
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 871us/step - accuracy: 0.6173 - f1_score: nan - loss: 0.6550
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 906us/step - accuracy: 0.6173 - f1_score: nan - loss: 0.6549

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 33ms/step
[1m 80/117[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 638us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 759us/step
Accuracy: 0.620
Precision: 0.609
Recall: 0.620
F_score: 0.612

              precision    recall  f1-score   support

           0       0.68      0.74      0.71      2323
           1       0.50      0.42      0.45      1419

    accuracy                           0.62      3742
   macro avg       0.59      0.58      0.58      3742
weighted avg       0.61      0.62      0.61      3742

2319 examples predicted correctly.
1190 examples predicted 1.
2552 examples predicted 0.
Completion time of the All concat NN model: 2.741 s = 0.046 min

==================================================================
SVM analysis for: All summed
==================================================================

Class ratio:  {0: 1.0, 1: 1.2954924874791318}

==================================================================
          Linear SVM
==================================================================

Accuracy: 0.660
Precision: 0.676
Recall: 0.660
F_score: 0.664

              precision    recall  f1-score   support

           0       0.76      0.67      0.71      2323
           1       0.54      0.65      0.59      1419

    accuracy                           0.66      3742
   macro avg       0.65      0.66      0.65      3742
weighted avg       0.68      0.66      0.66      3742


==================================================================
 Logistic Regression
==================================================================

Accuracy: 0.655
Precision: 0.672
Recall: 0.655
F_score: 0.659

              precision    recall  f1-score   support

           0       0.75      0.66      0.70      2323
           1       0.54      0.65      0.59      1419

    accuracy                           0.65      3742
   macro avg       0.65      0.65      0.65      3742
weighted avg       0.67      0.65      0.66      3742

Completion time of the All summed SVM model: 8.072 s = 0.135 min

==================================================================
NN analysis for: All summed
==================================================================


Building Bow NN model...
Model: "sequential_6"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense_12 (Dense)                     │ (None, 5)                   │             505 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_13 (Dense)                     │ (None, 1)                   │               6 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 511 (2.00 KB)
 Trainable params: 511 (2.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:17[0m 576ms/step - accuracy: 0.4375 - f1_score: nan - loss: 0.8589
[1m 55/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 941us/step - accuracy: 0.4445 - f1_score: nan - loss: 0.8170  
[1m105/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 969us/step - accuracy: 0.4403 - f1_score: nan - loss: 0.8089
[1m155/344[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 984us/step - accuracy: 0.4413 - f1_score: nan - loss: 0.7990
[1m210/344[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 966us/step - accuracy: 0.4445 - f1_score: nan - loss: 0.7893
[1m282/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 898us/step - accuracy: 0.4510 - f1_score: nan - loss: 0.7780
[1m331/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 918us/step - accuracy: 0.4559 - f1_score: nan - loss: 0.7714
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 941us/step - accuracy: 0.4574 - f1_score: nan - loss: 0.7696
Epoch 2/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m10s[0m 31ms/step - accuracy: 0.4375 - f1_score: nan - loss: 0.7123
[1m 50/344[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5603 - f1_score: nan - loss: 0.6778  
[1m100/344[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5798 - f1_score: nan - loss: 0.6740
[1m141/344[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5881 - f1_score: nan - loss: 0.6718
[1m187/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5926 - f1_score: nan - loss: 0.6702
[1m255/344[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - accuracy: 0.5974 - f1_score: nan - loss: 0.6681
[1m328/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 933us/step - accuracy: 0.6009 - f1_score: nan - loss: 0.6666
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 922us/step - accuracy: 0.6015 - f1_score: nan - loss: 0.6663
Epoch 3/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m7s[0m 23ms/step - accuracy: 0.5312 - f1_score: nan - loss: 0.6558
[1m 66/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 771us/step - accuracy: 0.6056 - f1_score: nan - loss: 0.6564
[1m122/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 830us/step - accuracy: 0.6147 - f1_score: nan - loss: 0.6526
[1m176/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 861us/step - accuracy: 0.6192 - f1_score: nan - loss: 0.6511
[1m235/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 860us/step - accuracy: 0.6226 - f1_score: nan - loss: 0.6500
[1m304/344[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 830us/step - accuracy: 0.6244 - f1_score: nan - loss: 0.6495
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 844us/step - accuracy: 0.6252 - f1_score: nan - loss: 0.6493
Epoch 4/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 27ms/step - accuracy: 0.7188 - f1_score: nan - loss: 0.6201
[1m 67/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 769us/step - accuracy: 0.6615 - f1_score: nan - loss: 0.6353
[1m136/344[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 753us/step - accuracy: 0.6529 - f1_score: nan - loss: 0.6391
[1m204/344[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 749us/step - accuracy: 0.6473 - f1_score: nan - loss: 0.6406
[1m268/344[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 757us/step - accuracy: 0.6449 - f1_score: nan - loss: 0.6410
[1m329/344[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 769us/step - accuracy: 0.6432 - f1_score: nan - loss: 0.6413
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 784us/step - accuracy: 0.6430 - f1_score: nan - loss: 0.6413
Epoch 5/5

[1m  1/344[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 27ms/step - accuracy: 0.6875 - f1_score: nan - loss: 0.5894
[1m 52/344[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 989us/step - accuracy: 0.6425 - f1_score: nan - loss: 0.6353
[1m112/344[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 907us/step - accuracy: 0.6447 - f1_score: nan - loss: 0.6345
[1m182/344[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 838us/step - accuracy: 0.6448 - f1_score: nan - loss: 0.6351
[1m236/344[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 861us/step - accuracy: 0.6454 - f1_score: nan - loss: 0.6347
[1m290/344[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 876us/step - accuracy: 0.6456 - f1_score: nan - loss: 0.6347
[1m344/344[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 855us/step - accuracy: 0.6455 - f1_score: nan - loss: 0.6348

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m13s[0m 120ms/step - accuracy: 0.8125 - f1_score: nan - loss: 0.5904
[1m 65/117[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 790us/step - accuracy: 0.6914 - f1_score: nan - loss: 0.6186 
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 810us/step - accuracy: 0.6434 - f1_score: nan - loss: 0.6452

[1m  1/117[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3s[0m 34ms/step
[1m 80/117[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 638us/step
[1m117/117[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 749us/step
Accuracy: 0.629
Precision: 0.616
Recall: 0.629
F_score: 0.619

              precision    recall  f1-score   support

           0       0.68      0.76      0.72      2323
           1       0.51      0.41      0.45      1419

    accuracy                           0.63      3742
   macro avg       0.60      0.59      0.59      3742
weighted avg       0.62      0.63      0.62      3742

2354 examples predicted correctly.
1127 examples predicted 1.
2615 examples predicted 0.
Completion time of the All summed NN model: 2.724 s = 0.045 min
Boxplot saved to D:\sarcasm detection/plots/bow_models/embeddings_nn_boxplot.png 
